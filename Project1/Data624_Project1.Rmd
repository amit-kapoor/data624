---
title: "Data624 - Project1"
author: "Amit Kapoor"
date: "3/28/2021"
output:
  html_document:
    highlight: pygments
    number_sections: no
    theme: flatly
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Overview

This project includes 3 time series dataset and requires to select best forecasting model for all 3 datasets.

* Part A - ATM Forecast 
* Part B - Forecasting Power
* Part C - Waterflow Pipe


```{r lib, include=FALSE, message=FALSE}
# Libraries
library(readxl)
library(ggplot2)
library(tidyverse)
library(psych)
library(forecast)
library(gridExtra)
library(fpp2)
library(urca)
```



# Part A - ATM Forecast 

The dataset contains cash withdrawals from 4 different ATM machines from May 2009 to Apr 2010. The variable ‘Cash’ is provided in hundreds of dollars and data is in a single file. Before starting our analysis we will first download the excel from github and then read it through read_excel.


## Exploratory Analysis

```{r warning=FALSE}
temp.file <- tempfile(fileext = ".xlsx")
download.file(url="https://github.com/amit-kapoor/data624/blob/main/Project1/ATM624Data.xlsx?raw=true", 
              destfile = temp.file, 
              mode = "wb", 
              quiet = TRUE)
atm.data <- read_excel(temp.file, skip=0, col_types = c("date","text","numeric"))

glimpse(atm.data)
```


```{r}
# rows missing values
atm.data[!complete.cases(atm.data),]
```


```{r}
ggplot(atm.data[complete.cases(atm.data),] , aes(x=DATE, y=Cash, col=ATM )) + 
  geom_line(show.legend = FALSE) + 
  facet_wrap(~ATM, ncol=1, scales = "free")
```


```{r}
ggplot(atm.data[complete.cases(atm.data),] , aes(x=Cash )) + 
  geom_histogram(bins=20) + 
  facet_grid(cols=vars(ATM), scales = "free")
```


```{r}
# consider complete cases
atm.comp <- atm.data[complete.cases(atm.data),]
# pivot wider with cols from 4 ATMs and their values as Cash
atm.comp <- atm.comp %>% pivot_wider(names_from = ATM, values_from = Cash)
head(atm.comp)
```

```{r}
# summary
atm.comp %>% select(-DATE) %>% summary()
```



Per above exploratory analysis, all ATMs show different patterns. We would perform forecasting for each ATM separately.

* ATM1 and ATM2 shows similar pattern (approx.) throughout the time. ATM1 and ATM2 have 3 and 2 missing entries respectively.
* ATM3 appears to become online in last 3 days only and rest of days appears inactive. So tha data available for this ATM is very limited.
* ATM4 requires replacement for outlier and we can assume that one day spike of cash withdrawal is unique. It has an outlier showing withdrawl amount 10920.


## Data Cleaning

For this part we will first apply ts() function to get required time series. Next step is to apply tsclean function that will handle missing data along with outliers. To estimate missing values and outlier replacements, this function uses linear interpolation on the (possibly seasonally adjusted) series. Once we get the clean data we will use pivot_longer to get the dataframe in its original form.

```{r}
atm.ts <- ts(atm.comp %>% select(-DATE))
head(atm.ts)
```



```{r}
# apply tsclean
atm.ts.cln <- sapply(X=atm.ts, tsclean)
atm.ts.cln %>% summary()
```

If we compare this summary with previous one of original data, ATM1 and ATM2 has nomore NAs and ATM4 outlier value (10919.762) is handled and now the max value is 1712.075.

```{r}
# convert into data frame, pivot longer , arrange by ATM and bind with dates
atm.new <- as.data.frame(atm.ts.cln) %>% 
  pivot_longer(everything(), names_to = "ATM", values_to = "Cash") %>% 
  arrange(ATM)

atm.new <- cbind(DATE = seq(as.Date("2009-05-1"), as.Date("2010-04-30"), length.out=365), 
                 atm.new)

head(atm.new)
```




```{r}
ggplot(atm.new , aes(x=DATE, y=Cash, col=ATM )) + 
  geom_line(show.legend = FALSE) + 
  facet_wrap(~ATM, ncol=1, scales = "free")
```

Though above plot doesn't show much differences for ATM1,2,3 but tsclean handled the ATM4 data very well after replacing the outlier.


## Time Series


Function to plot forecast for various models.

```{r func-fcst}
# function to plot forecast(s)
atm.forecast <- function(timeseries) {
  # lambda value
  lambda <- BoxCox.lambda(timeseries)
  # models for forecast
  hw.model <- timeseries %>% hw(h=31, seasonal = "additive", lambda = lambda, damped = TRUE)
  ets.model <- timeseries %>% ets(lambda = lambda)
  arima.model <- timeseries %>% auto.arima(lambda = lambda)
  # forecast
  atm.hw.fcst <- forecast(hw.model, h=31)
  atm.ets.fcst <- forecast(ets.model, h=31)
  atm.arima.fcst <- forecast(arima.model, h=31)
  # plot forecasts
  p1 <- autoplot(timeseries) + 
    autolayer(atm.hw.fcst, PI=FALSE, series="Holt-Winters") + 
    autolayer(atm.ets.fcst, PI=FALSE, series="ETS") + 
    autolayer(atm.arima.fcst, PI=FALSE, series="ARIMA") + 
    theme(legend.position = "top") + 
    ylab("Cash Withdrawl") 
  # zoom in plot
  p2 <- p1 + 
    labs(title = "Zoom in ") + 
    xlim(c(51,56))
  
  grid.arrange(p1,p2,ncol=1)

}
```


Function to calculate RMSEs for various models.


```{r rmse}
model_accuracy <- function(timeseries, atm_num) {
  # lambda value
  lambda <- BoxCox.lambda(timeseries)
  
  # split the data to train and test
  train <- window(timeseries, end=c(40, 3))
  test <- window(timeseries, start=c(40, 4))
  
  # models for forecast
  hw.model <- train %>% hw(h=length(train), seasonal = "additive", lambda = lambda, damped = TRUE)
  ets.model <- train %>% ets(model='ANA', lambda = lambda)
  
  # Arima model
  if (atm_num == 1) {
    # for ATM1
    arima.model <- train %>% Arima(order=c(0,0,2), 
                                        seasonal = c(0,1,1), 
                                        lambda = lambda)
  } else if(atm_num == 2) {
    # for ATM2
    arima.model <- train %>% Arima(order=c(3,0,3), 
                                        seasonal = c(0,1,1), 
                                        include.drift = TRUE, 
                                        lambda = lambda,
                                        biasadj = TRUE)
  } else {
    # for ATM4
    arima.model <- train %>% Arima(order=c(0,0,1), 
                                    seasonal = c(2,0,0), 
                                    lambda = lambda)
  }
  
  # forecast
  hw.frct = forecast(hw.model, h = length(test))$mean
  ets.frct = forecast(ets.model, h = length(test))$mean
  arima.frct = forecast(arima.model, h = length(test))$mean
  
  # dataframe having rmse
  rmse = data.frame(RMSE=cbind(accuracy(hw.frct, test)[,2],
                                   accuracy(ets.frct, test)[,2],
                                   accuracy(arima.frct, test)[,2]))
  names(rmse) = c("Holt-Winters", "ETS", "ARIMA")
  # display rmse
  rmse
}
```


### ATM1

Seeing the time series plot, it is clear that there is a seasonality in the data. We can see increasing and decreasing activities over the weeks in below plot. From the ACF plot, we can see a slight decrease in every 7th lag due to trend. PACF plot shows some significant lags at the beginning. 


```{r atm1}
atm1.ts <- atm.new %>% filter(ATM=="ATM1") %>% select(Cash) %>% ts(frequency = 7)
ggtsdisplay(atm1.ts, main="ATM1 Cash Withdrawal", ylab="cash withdrawal", xlab="week")
```


From the above plots it is evident that the time series is non stationary, showing seasonality and will require differencing to make it stationary.


```{r}
ggsubseriesplot(atm1.ts, main="ATM1 Cash Withdrawal")
```

From the subseries plot, it is apparent that Tuesdays having highest mean of ash withdrawl while Saturdays being the lowest.

Next step is to apply BoxCox transformation. With $\lambda$ being 0.26, the resulting transformation does handle the variablity in time series as shown in below transformed plot.

```{r}
atm1.lambda <- BoxCox.lambda(atm1.ts)
atm1.ts.bc <- BoxCox(atm1.ts, atm1.lambda )
ggtsdisplay(atm1.ts.bc, main=paste("ATM1 Cash Withdrawal",round(atm1.lambda, 3)), ylab="cash withdrawal", xlab="week")
```

Next we will see the number of differences required for a stationary series and the number of differences required for a seasonally stationary series.


```{r}
# Number of differences required for a stationary series
ndiffs(atm1.ts.bc)
```

```{r}
# Number of differences required for a seasonally stationary series
nsdiffs(atm1.ts.bc)
```

It shows number of differences required for a seasonality stationary series is 1. Next step is to check kpss summary.

```{r}
atm1.ts.bc %>% diff(lag=7) %>% ur.kpss() %>% summary()
```


We can see the test statistic small and well within the range we would expect for stationary data. So we can conclude that the data are stationary.


```{r}
atm1.ts.bc %>% diff(lag=7) %>% ggtsdisplay()
```


The data is non-stationary with seasonality so there will be a seasonal difference of 1. Finally, the differencing of the data has now made it stationary. From the ACF plot, it is apparent now that there is a significant spike at lag 7 but none beyond lag 7.

Lets start with Holt-Winter’s additive model with damped trend since the seasonal variations are roughly constant through out the series.

```{r}
# Holt Winters with damped True
atm1.ts %>% hw(h=31, seasonal = "additive", lambda = atm1.lambda, damped = TRUE)
```

Next is to apply exponential smoothing method on this time series. It shows that the ETS(A, N, A) model best fits for the transformed ATM4, i.e. exponential smoothing with additive error, no trend component and additive seasonality.


```{r}
atm1.ts %>% ets(lambda = atm1.lambda )
```


Next we will find out the appropriate ARIMA model for this time series. The suggested model seems ARIMA(0,0,2)(0,1,1)[7].


```{r}
atm1.fit3 <- atm1.ts %>% auto.arima(lambda = atm1.lambda )
atm1.fit3
```


Next is to see residuals time series plot which shows residuals are being near normal with mean of the residuals being near to zero. Also there is no significant autocorrelation that confirms that forecasts are good.

```{r}
checkresiduals(atm1.fit3)
```

Let's plot the forecast for all the considered models above which will shows a nice visual comparison. it will also show a zoomed in plot to have a clearer view.


```{r}
atm.forecast(atm1.ts)
```



```{r}
model_accuracy(atm1.ts,1)
```


### ATM2


From the time series plot, it is apparent that there is a seasonality in the data but dont see a trend over the period. ACF shows teh significant lags at 7,14 and 21 confirming seasonality. From the PACF, there are few significant lags at the beginning but others within critical limit. Overall, it is non stationary, having seasonality and would require differencing for it to become stationary.


```{r atm2}
atm2.ts <- atm.new %>% filter(ATM=="ATM2") %>% select(Cash) %>% ts(frequency = 7)
ggtsdisplay(atm2.ts, main="ATM2 Cash Withdrawal", ylab="cash withdrawal", xlab="week")
```

From the subseries plot, it is clear that Sunday is having highest mean for cash withdrawl while Saturday has the lowest.


```{r}
ggsubseriesplot(atm2.ts, main="ATM2 Cash Withdrawal")
```

Next step is to apply BoxCox transformation. With $\lambda$ being 0.72, the resulting transformation does handle the variablity in time series as shown in below transformed plot.


```{r}
atm2.lambda <- BoxCox.lambda(atm2.ts)
atm2.ts.bc <- BoxCox(atm2.ts, atm2.lambda )
ggtsdisplay(atm2.ts.bc, main=paste("ATM2 Cash Withdrawal",round(atm2.lambda, 3)), ylab="cash withdrawal", xlab="week")
```


```{r}
# Number of differences required for a stationary series
ndiffs(atm2.ts.bc)
```


```{r}
# Number of differences required for a seasonally stationary series
nsdiffs(atm2.ts.bc)
```

It shows number of differences required is 1 for boxcox transformed data.

```{r}
atm2.ts.bc %>% diff(lag=7) %>% ur.kpss() %>% summary()
```


We can see the test statistic small and well within the range we would expect for stationary data. So we can conclude that the data are stationary



```{r}
atm2.ts.bc %>% diff(lag=7) %>% ggtsdisplay()
```


First we will start with Holt-Winters damped method. Damping is possible with both additive and multiplicative Holt-Winters’ methods. This method often provides accurate and robust forecasts for seasonal data is the Holt-Winters method with a damped trend.


```{r}
# Holt Winters
atm2.ts %>% hw(h=31, seasonal = "additive", lambda = atm2.lambda, damped = TRUE)
```

Next is to apply exponential smoothing method on this time series. It shows that the ETS(A, N, A) model best fits for the transformed ATM4, i.e. exponential smoothing with additive error, no trend component and additive seasonality.

```{r}
# ETS
atm2.ts %>% ets(lambda = atm2.lambda)
```



We will now find out the appropriate ARIMA model for this time series. The suggested model seeems ARIMA(3,0,3)(0,1,1)[7] with drift.


```{r}
atm2.fit3 <- atm2.ts %>% auto.arima(lambda = atm2.lambda )
atm2.fit3
```


Next is to see residuals time series plot which shows residuals are being near normal with mean of the residuals being near to zero. Also there is no significant autocorrelation that confirms that forecasts are good.

```{r}
checkresiduals(atm2.fit3)
```

Next step is to plot the forecast for all the considered models above which will shows a nice visual comparison. it will also show a zoomed in plot to have a clearer view.


```{r}
atm.forecast(atm2.ts)
```


```{r}
model_accuracy(atm2.ts,2)
```


### ATM3


```{r atm3}
atm3.ts <- atm.new %>% filter(ATM=="ATM3") %>% select(Cash) %>% ts(frequency = 7)
autoplot(atm3.ts, main="ATM3 Cash Withdrawal", ylab="cash withdrawal", xlab="week")
```





### ATM4

Seeing the time series plot, it is apparent that there is seasonality in this series. ACF shows a decrease in every 7th lag. From the PACF, there are few significant lags at the beginning but others within critical limit. Overall, it is non stationary, having seasonality and might require differencing for it to become stationary.



```{r atm4}
atm4.ts <- atm.new %>% filter(ATM=="ATM4") %>% select(Cash) %>% ts(frequency = 7)
ggtsdisplay(atm4.ts, main="ATM4 Cash Withdrawal", ylab="cash withdrawal", xlab="week")
```

From the subseries plot, it is clear that Sunday is having highest mean for cash withdrawl while Saturday has the lowest.

```{r}
ggsubseriesplot(atm4.ts, main="ATM4 Cash Withdrawal")
```

Next step is to apply BoxCox transformation. With $\lambda$ being 0.45, the resulting transformation does handle the variablity in time series as shown in below transformed plot.


```{r}
atm4.lambda <- BoxCox.lambda(atm4.ts)
atm4.ts.bc <- BoxCox(atm4.ts, atm4.lambda )
ggtsdisplay(atm4.ts.bc, main=paste("ATM4 Cash Withdrawal",round(atm4.lambda, 3)), ylab="cash withdrawal", xlab="week")
```


```{r}
# Number of differences required for a stationary series
ndiffs(atm4.ts.bc)
```


```{r}
# Number of differences required for a seasonally stationary series
nsdiffs(atm4.ts.bc)
```


It shows number of differences required is 0 for boxcox transformed data. 


```{r}
atm4.ts.bc %>% ur.kpss() %>% summary()
```


We can see the test statistic small and well within the range we would expect for stationary data. So we can conclude that the data are stationary.


```{r}
atm4.ts.bc %>% ggtsdisplay()
```


First we will start with Holt-Winters damped method. Damping is possible with both additive and multiplicative Holt-Winters’ methods. This method often provides accurate and robust forecasts for seasonal data is the Holt-Winters method with a damped trend.


```{r}
# Holt Winters
atm4.ts %>% hw(h=31, seasonal = "additive", lambda = atm4.lambda, damped = TRUE)
```


Next is to apply exponential smoothing method on this time series. It shows that the ETS(A, N, A) model best fits for the  transformed ATM4, i.e. exponential smoothing with additive error, no trend component and additive seasonality.

```{r}
# ETS
atm4.ts %>% ets(lambda = atm4.lambda)
```


Next we will find out the appropriate ARIMA model for this time series. The suggested model seeems ARIMA(0,0,1)(2,0,0)[7] with non-zero mean.

```{r}
# Arima
atm4.fit3 <- atm4.ts %>% auto.arima(lambda = atm4.lambda)
atm4.fit3
```

Next is to see residuals time series plot which shows residuals are being near normal with mean of the residuals being near to zero. Also there is no significant autocorrelation that confirms that forecasts are good.

```{r}
checkresiduals(atm4.fit3)
```



Next is to plot the forecast for all the considered models above which will shows a nice visual comparison. it will also show a zoomed in plot to have a clearer view.

```{r}
atm.forecast(atm4.ts)
```




```{r}
model_accuracy(atm4.ts,4)
```

## Forecast May, 2010



# Part B - Forecasting Power

```{r warning=FALSE}

download.file(
  url="https://github.com/amit-kapoor/data624/blob/main/Project1/ResidentialCustomerForecastLoad-624.xlsx?raw=true", 
  destfile = temp.file, 
  mode = "wb", 
  quiet = TRUE)
power.data <- read_excel(temp.file, skip=0, col_types = c("numeric","text","numeric"))

head(power.data)
```

## Exploratory Analysis


```{r}
power.data$`YYYY-MMM` <- paste0(power.data$`YYYY-MMM`,"-01")
power.data$Date <- lubridate::ymd(power.data$`YYYY-MMM`)

ggplot(power.data, aes(x=Date, y=KWH )) + 
  geom_line(color="darkblue")
```


## Data Cleaning

```{r}
power.ts <- ts(power.data$KWH, start=c(1998, 1), frequency = 12)
head(power.ts)
```



```{r}
power.ts <- tsclean(power.ts)
power.ts %>% summary()
```



## Timeseries


```{r}
ggtsdisplay(power.ts, main="Residential Power Usage", ylab="Power Used", xlab="Month")
```


```{r}
ggsubseriesplot(power.ts, main="Pwer Usage Subseries Plot", ylab="Power Used")
```


```{r}
ggseasonplot(power.ts, polar=TRUE, main="Power Usage Seasonal Plot", ylab="Power Used")
```


```{r}
gglagplot(power.ts )
```


```{r pow-fcst}

# function to plot forecast(s)
power.forecast <- function(timeseries) {
  # lambda value
  lambda <- BoxCox.lambda(timeseries)
  
  # models for forecast
  hwa.model <- timeseries %>% hw(h=12, seasonal = "additive", lambda = lambda, damped = TRUE)
  hwm.model <- timeseries %>% hw(h=12, seasonal = "multiplicative", damped = TRUE)
  ets.model <- timeseries %>% ets(lambda = lambda )
  arima.model <- timeseries %>% auto.arima(lambda = lambda, biasadj = TRUE)
  
  # forecast
  pow.hwa.fcst <- forecast(hwa.model, h=12)
  pow.hwm.fcst <- forecast(hwm.model, h=12)
  pow.ets.fcst <- forecast(ets.model, h=12)
  pow.arima.fcst <- forecast(arima.model, h=12)
  
  # plot forecasts
  p1 <- autoplot(timeseries) + 
    autolayer(pow.hwa.fcst, PI=FALSE, series="Holt-Winters Additive") + 
    autolayer(pow.hwm.fcst, PI=FALSE, series="Holt-Winters Multiplicative") + 
    autolayer(pow.ets.fcst, PI=FALSE, series="ETS") + 
    autolayer(pow.arima.fcst, PI=FALSE, series="ARIMA") + 
    theme(legend.position = "top") + 
    ylab("Power Used") 
  
  # zoom in plot
  p2 <- p1 + 
    labs(title = "Zoom in ") + 
    xlim(c(2012,2015))
  
  grid.arrange(p1,p2,ncol=1)

}
```



```{r rmse1}
powm_accuracy <- function(timeseries) {
  # lambda value
  lambda <- BoxCox.lambda(timeseries)
  
  # split the data to train and test
  train <- window(timeseries, end=c(2009, 12))
  test <- window(timeseries, start=2010)
  
  # models for forecast
  hwa.model <- train %>% hw(h=length(train), seasonal = "additive", lambda = lambda, damped = TRUE)
  hwm.model <- train %>% hw(h=length(train), seasonal = "multiplicative", damped = TRUE)
  ets.model <- train %>% ets(model="AAA", lambda = lambda, biasadj = TRUE)
  arima.model <- train %>% Arima(order=c(0,0,1), 
                                        seasonal = c(2,1,0), 
                                        include.drift = TRUE, 
                                        lambda = lambda,
                                        biasadj = TRUE)
  
  
  # forecast
  hwa.frct = forecast(hwa.model, h = length(test))$mean
  hwm.frct = forecast(hwm.model, h = length(test))$mean
  ets.frct = forecast(ets.model, h = length(test))$mean
  arima.frct = forecast(arima.model, h = length(test))$mean
  
  # dataframe having rmse
  rmse = data.frame(RMSE=cbind(accuracy(hwa.frct, test)[,2],
                               accuracy(hwm.frct, test)[,2],
                               accuracy(ets.frct, test)[,2],
                              accuracy(arima.frct, test)[,2]))
  names(rmse) = c("Holt-Winters Additive", "Holt-Winters Multiplicative", "ETS", "ARIMA")
  
  # display rmse
  rmse
}
```



```{r}
powerts.lambda <- BoxCox.lambda(power.ts)
power.ts.bc <- BoxCox(power.ts, powerts.lambda )
ggtsdisplay(power.ts, main=paste("Residential Power Usage",round(powerts.lambda, 3)), ylab="Power Used", xlab="Month")

```

```{r}
# Number of differences required for a stationary series
ndiffs(power.ts.bc)
```


```{r}
# Number of differences required for a seasonally stationary series
nsdiffs(power.ts.bc)
```


It shows number of differences required is 1 for boxcox transformed data. 


```{r}
power.ts.bc %>% diff(lag=12) %>% ur.kpss() %>% summary()
```


We can see the test statistic small and well within the range we would expect for stationary data. So we can conclude that the data are stationary.


```{r}
power.ts.bc %>% 
  diff(lag=12) %>% 
  ggtsdisplay(main="Residential Power Usage", ylab="Power Used", xlab="Month")
```



```{r}
# Holt Winters additive with damped True
power.ts %>% hw(h=31, seasonal = "additive", lambda = powerts.lambda, damped = TRUE)
```

```{r}
# Holt Winters multiplicative with damped True
power.ts %>% hw(h=31, seasonal = "multiplicative", damped = TRUE)
```


```{r}
power.ts %>% ets(lambda = powerts.lambda, biasadj = TRUE)
```



```{r}
power.fit4 <- power.ts %>% auto.arima(lambda = powerts.lambda, biasadj = TRUE)
power.fit4
```


```{r}
checkresiduals(power.fit4)
```

```{r}
power.forecast(power.ts)
```



```{r}
powm_accuracy(power.ts)
```

## Forecast 2014



# Part C - Waterflow Pipe

```{r warning=FALSE}

download.file(url="https://github.com/amit-kapoor/data624/blob/main/Project1/Waterflow_Pipe1.xlsx?raw=true", 
              destfile = temp.file, 
              mode = "wb", 
              quiet = TRUE)
pipe1.data <- read_excel(temp.file, skip=0, col_types = c("date","numeric"))

download.file(url="https://github.com/amit-kapoor/data624/blob/main/Project1/Waterflow_Pipe2.xlsx?raw=true", 
              destfile = temp.file, 
              mode = "wb", 
              quiet = TRUE)

pipe2.data <- read_excel(temp.file, skip=0, col_types = c("date","numeric"))
head(pipe1.data)
```


