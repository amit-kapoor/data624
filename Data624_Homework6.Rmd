---
title: "Data624 - Homework6"
author: "Amit Kapoor"
date: "3/16/2021"
output:
  html_document:
    highlight: pygments
    number_sections: no
    theme: flatly
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r loadData, include=FALSE}
# Libraries
library(fpp2)
library(tidyverse)
library(urca)
```



# Exercise 8.1
**Figure 8.31 shows the ACFs for 36 random numbers, 360 random numbers, and 1,000 random numbers.**

## a
**Explain the differences among these figures. Do they all indicate that the data are white noise?**

<center>
![Picture 1](https://raw.githubusercontent.com/amit-kapoor/data624/master/HW6_1.png)
</center>

As sample size increases (from 36 random number to 360 random numbers and then 1,000 random numbers), the correlation tends to 0.The ACF bands keeps on getting narrower and random numbers size increases. If the number of spikes are more than 5% that are outside the bounds than series is not white noise. In each of these ACF plots, that is not the case as all the bars are close to 0 so all are of white noise.


## b
**Why are the critical values at different distances from the mean of zero? Why are the autocorrelations different in each figure when they each refer to white noise?**


The critical values are at different distances from the mean of zero since critical values for white noise are supposed to lie within $\pm \frac{1.96}{\sqrt{T}}$ where T is length of time series. In this case, as T gets bigger, range gets smaller. Hence the autocorrelations different in each figure.

# Exercise 8.2
**A classic example of a non-stationary series is the daily closing IBM stock price series (data set `ibmclose`). Use R to plot the daily closing prices for IBM stock and the ACF and PACF. Explain how each plot shows that the series is non-stationary and should be differenced.**

```{r ibc-data}
head(ibmclose)
```


```{r ibc-plot}
ggtsdisplay(ibmclose, main="Daily closing IBM stock price", ylab="Stock Price", xlab="Days")
```

This time series does show the trend e.g. from 210 to 270 it shows the downward trend. the ACF plot is useful for identifying non-stationary time series. For a non stationary time series, the ACF plot decreases slowly. Here the ACF plot does show a slow decrease as the lag increases.The PACF plot is a plot of the partial correlation coefficients between the series and lags of itself. Here PACF plot shows the first lag is close to 1 and all the other PACF is close to 0. Thus we can conclude it is a non-stationary time series and should be differenced to make it stationary.


# Exercise 8.3
For the following series, find an appropriate Box-Cox transformation and order of differencing in order to obtain stationary data.

## a
`usnetelec`

```{r usnetelec}
#Annual US net electricity generation (billion kwh) for 1949-2003
head(usnetelec)
```


```{r disp1}
ggtsdisplay(usnetelec, 
            main="Annual US net electricity generation", 
            ylab="billion kwh", 
            xlab="year")
```

The graph and ACF plot show an upward trend for this time series. PACF shows all the lags close to 0 except the 1st one which is close to 1. It confirms this a non stationary time series.

Now lets do the BoxCox transformation and see the results.

```{r disp1-boxcox}
bc_trans <- BoxCox(usnetelec, BoxCox.lambda(usnetelec))
ggtsdisplay(bc_trans, 
            main="Annual US net electricity generation - BoxCox", 
            ylab="billion kwh", 
            xlab="year")
```

After BoxCox transformation of given time series, we dont see noticeable change here which could be due to non seasonalilty in time series. Next is to use kpss test in which the null hypothesis is that the data are stationary, and we look for evidence that the null hypothesis is false. Consequently, small p-values (e.g., less than 0.05) suggest that differencing is required. 


```{r bct1-kpss}
bc_trans %>% ur.kpss() %>% summary()
```

The test statistic is much bigger than the 1% critical value, indicating that the null hypothesis is rejected and the boxcox transformed data is not stationary. We will now use ndiffs() function to determine the order of differencing.

```{r}
ndiffs(bc_trans)
```

It shows number of differences required is 2 for boxcox transformed data. Lets first apply the differences as 1 and see the results.


```{r}
bct.diff <- bc_trans %>% diff()
bct.diff %>% ur.kpss() %>% summary()
```


We can see the diff of order 1 makes the test statistic small and well within the range we would expect for stationary data. So we can conclude that the differenced data are stationary.


```{r}
ggtsdisplay(bct.diff, 
            main="Annual US net electricity generation", 
            ylab="billion kwh", 
            xlab="year")
```




## b
`usgdp`

```{r}
ggtsdisplay(usgdp)
```






## c
`mcopper`

```{r}
ggtsdisplay(mcopper)
```


## d
`enplanements`

```{r}
ggtsdisplay(enplanements)
```


## e
`visitors`


```{r}
ggtsdisplay(visitors)
```


# Exercise 8.5
For your retail data (from Exercise 3 in Section 2.10), find the appropriate order of differencing (after transformation if necessary) to obtain stationary data.


# Exercise 8.6
Use R to simulate and plot some data from simple ARIMA models.

## a
Use the following R code to generate data from an AR(1) model with $\phi_1 = 0.6$ and $\sigma^2 = 1$. The process starts with $y_1 = 0$.

## b
Produce a time plot for the series. How does the plot change as you change $\phi_1$?

## c
Write your own code to generate data from an MA(1) model with $\theta_1 = 0.6$ and $\sigma^2=1$.


## d
Produce a time plot for the series. How does the plot change as you change $\theta_1$?



## e
Generate data from an ARMA(1,1) model with $\phi_1=0.6$, $\theta_1=0.6$ and $\sigma^2=1$.



## f
Generate data from an AR(2) model with $\phi_1=-0.8$, $\phi_2=0.3$ and $\sigma^2=1$. (Note that these parameters will give a non-stationary series.)


## g
Graph the latter two series and compare them.



# Exercise 8.7
Consider `wmurders`, the number of women murdered each year (per 100,000 standard population) in the United States.

## a
By studying appropriate graphs of the series in R, find an appropriate ARIMA(p,d,q) model for these data.


## b
Should you include a constant in the model? Explain.

## d 
Fit the model using R and examine the residuals. Is the model satisfactory?


## e
Forecast three times ahead. Check your forecasts by hand to make sure that you know how they have been calculated.


## f
Create a plot of the series with forecasts and prediction intervals for the next three periods shown.


## g
Does `auto.arima()` give the same model you have chosen? If not, which model do you think is better?

























