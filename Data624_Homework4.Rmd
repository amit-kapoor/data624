---
title: "Data624 - Homework4"
author: "Amit Kapoor"
date: "2/28/2021"
output:
  pdf_document:
    toc: yes
  html_document:
    highlight: pygments
    number_sections: no
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r include=TRUE, message=FALSE, warning=FALSE}
library(mlbench)
library(DataExplorer)
library(GGally)
library(psych)
library(caret)
library(summarytools)
library(naniar)
```

## 3.1
**The UC Irvine Machine Learning Repository6 contains a data set related to glass identification. The data consist of 214 glass samples labeled as one of seven class categories. There are nine predictors, including the refractive index and percentages of eight elements: Na, Mg, Al, Si, K, Ca, Ba, and Fe.**

The data can be accessed via:

```{r loadData}
data(Glass)
str(Glass)
```



**(a) Using visualizations, explore the predictor variables to understand their distributions as well as the relationships between predictors.**

```{r}
# predictors distribution
plot_histogram(Glass, 
               geom_histogram_args = list(bins = 30L), 
               nrow = 3L,
               ncol = 3L)
```

```{r message=FALSE, warning=FALSE}
# scatterplot matrix
Glass %>% 
  dplyr::select(-Type) %>%
  ggpairs(title = "Paiwise scatter plots") %>% 
  print(progress = F)
```


```{r}
# correlation
Glass %>% 
  dplyr::select(-Type) %>%
  ggcorr(label = TRUE)
```



**(b) Do there appear to be any outliers in the data? Are any predictors skewed?**


```{r}
describe(Glass)
```


```{r}
# function to get skewness and number of outliers
label <- function(var) {
  return( paste("skew=" , round(describe(var)$skew,2) , "outliers=" , length(boxplot(var, plot=FALSE)$out)) )
}

par(mfrow=c(3,3))
for (i in 1:9){
  boxplot(
    Glass[i], color='green', horizontal = T, 
    xlab = label(Glass[i])
    )
}
```



**(c) Are there any relevant transformations of one or more predictors that might improve the classification model?**





```{r}
glass_boxcox_t <- preProcess(Glass, method = c("BoxCox"))
glass_boxcox_t
```




```{r}
trans_boxcox <- predict(glass_boxcox_t, Glass)
```





```{r}
plot_histogram(trans_boxcox, 
               geom_histogram_args = list(bins = 30L), 
               nrow = 3L,
               ncol = 3L)
```




```{r message=FALSE, warning=FALSE}
# scatterplot matrix
trans_boxcox %>% 
  #dplyr::select(-Type) %>%
  ggpairs(title = "Paiwise scatter plots") %>% 
  print(progress = F)
```




```{r}
glass_bcpca_t <- preProcess(Glass, method = c("BoxCox", "pca"))
glass_bcpca_t
```




```{r}
trans_bcpca <- predict(glass_bcpca_t, Glass)
```



```{r}
plot_histogram(trans_bcpca, 
               geom_histogram_args = list(bins = 30L), 
               nrow = 3L,
               ncol = 3L)
```


```{r message=FALSE, warning=FALSE}
# scatterplot matrix
trans_bcpca %>% 
  #dplyr::select(-Type) %>%
  ggpairs(title = "Paiwise scatter plots") %>% 
  print(progress = F)
```


## 3.2
**The soybean data can also be found at the UC Irvine Machine Learning Repository. Data were collected to predict disease in 683 soybeans. The 35 predictors are mostly categorical and include information on the environmental conditions (e.g., temperature, precipitation) and plant conditions (e.g., left spots, mold growth). The outcome labels consist of 19 distinct classes.**

The data can be loaded via:

```{r}
data(Soybean)
str(Soybean)
```


**(a) Investigate the frequency distributions for the categorical predictors. Are any of the distributions degenerate in the ways discussed earlier in this chapter?**

```{r}
dfSummary(Soybean, graph.col = F)
```


**(b) Roughly 18% of the data are missing. Are there particular predictors that are more likely to be missing? Is the pattern of missing data related to the classes?**


```{r}
gg_miss_var(Soybean) + labs(y = "All missing ones")
```

```{r}
gg_miss_fct(x=Soybean, fct=Class)
```


**(c) Develop a strategy for handling missing data, either by eliminating predictors or imputation.**





